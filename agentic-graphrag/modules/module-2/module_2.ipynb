{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbEPC67g5c96"
      },
      "source": [
        "# Module 2: Knowledge Graph Construction & Embedding\n",
        "\n",
        "Welcome to Module 2! In the previous module, we successfully extracted structured data from our raw contract files into `contract_data.json`. Now, we'll complete the **Ingestion Pipeline** by taking that structured data and using it to build our AGL Knowledge Graph.\n",
        "\n",
        "**Our Mission:**\n",
        "1. Connect to a Neo4j database.\n",
        "2. Generate vector embeddings for our contract summaries.\n",
        "3. Ingest both the structured data and the embeddings into Neo4j to create a fully queryable knowledge graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywCgiNgd5c98"
      },
      "source": [
        "## 1. Setup and Dependencies\n",
        "\n",
        "Let's start by installing the required libraries. We need `langchain-neo4j` to interact with our graph database and `langchain-google-genai` for creating embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gkwDiFoc5c98"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain-neo4j langchain-google-genai python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AvLyltqA5c99"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from dotenv import load_dotenv\n",
        "from google.colab import userdata\n",
        "\n",
        "from langchain_neo4j import Neo4jGraph\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "from google.colab import drive\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euJapZle5c9-"
      },
      "source": [
        "## 2. Configure Environment Variables\n",
        "\n",
        "This module requires two sets of credentials:\n",
        "1.  **Google API Key:** To use the embedding model.\n",
        "2.  **Neo4j Database Credentials:** To connect to our graph database.\n",
        "\n",
        "**Action:** You can get free Neo4j AuraDB credentials from [Neo4j's website](https://neo4j.com/cloud/platform/aura-graph-database/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSdr-_4H5c9-",
        "outputId": "383ebaf7-ae40-407b-ca61-e850e16b3f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ GOOGLE_API_KEY: Set successfully\n",
            "‚úÖ NEO4J_URI: Set successfully\n",
            "‚úÖ NEO4J_USERNAME: Set successfully\n",
            "‚úÖ NEO4J_PASSWORD: Set successfully\n",
            "‚úÖ NEO4J_DATABASE: Set successfully\n",
            "\n",
            "üéâ Successfully loaded all 5 required environment variables!\n",
            "‚úÖ Google API key format looks valid\n"
          ]
        }
      ],
      "source": [
        "# Define required environment variables\n",
        "required_vars = [\"GOOGLE_API_KEY\", \"NEO4J_URI\", \"NEO4J_USERNAME\", \"NEO4J_PASSWORD\", \"NEO4J_DATABASE\"]\n",
        "\n",
        "# Set environment variables with validation\n",
        "missing_vars = []\n",
        "for var in required_vars:\n",
        "    value = userdata.get(var)\n",
        "    if value:\n",
        "        os.environ[var] = value\n",
        "        print(f\"‚úÖ {var}: Set successfully\")\n",
        "    else:\n",
        "        missing_vars.append(var)\n",
        "        print(f\"‚ùå {var}: Missing or empty\")\n",
        "\n",
        "# Check if all required variables are set\n",
        "if missing_vars:\n",
        "    print(f\"\\nüö® Error: Missing required environment variables: {', '.join(missing_vars)}\")\n",
        "    print(\"Please ensure all secrets are properly configured in Colab.\")\n",
        "    raise ValueError(f\"Missing environment variables: {missing_vars}\")\n",
        "else:\n",
        "    print(f\"\\nüéâ Successfully loaded all {len(required_vars)} required environment variables!\")\n",
        "\n",
        "# Optional: Verify API key format (basic validation)\n",
        "if os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "    api_key = os.environ[\"GOOGLE_API_KEY\"]\n",
        "    if len(api_key) < 20:  # Basic length check\n",
        "        print(\"‚ö†Ô∏è  Warning: Google API key seems unusually short\")\n",
        "    else:\n",
        "        print(\"‚úÖ Google API key format looks valid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWqWbHn75c9-"
      },
      "source": [
        "## 3. Connect to Neo4j and Clear Existing Data\n",
        "\n",
        "Let's establish a connection to our database. For a clean start, we'll also run a query to delete any existing data in the graph. This ensures our ingestion pipeline is repeatable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI8K5IXb5c9-",
        "outputId": "a9dbf16a-3016-4efc-ad25-e290c4bfd0eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to connect to Neo4j (attempt 1/3)...\n",
            "‚úÖ Neo4j connection established successfully\n",
            "üßπ Clearing existing data...\n",
            "‚úÖ Successfully connected to Neo4j and cleared existing data.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from neo4j.exceptions import ServiceUnavailable, TransientError\n",
        "\n",
        "max_connection_retries = 3\n",
        "connection_delay = 2\n",
        "\n",
        "for attempt in range(max_connection_retries):\n",
        "    try:\n",
        "        print(f\"Attempting to connect to Neo4j (attempt {attempt + 1}/{max_connection_retries})...\")\n",
        "\n",
        "        graph = Neo4jGraph(\n",
        "            url=os.environ[\"NEO4J_URI\"],\n",
        "            username=os.environ[\"NEO4J_USERNAME\"],\n",
        "            password=os.environ[\"NEO4J_PASSWORD\"],\n",
        "            database=os.environ[\"NEO4J_DATABASE\"]\n",
        "        )\n",
        "\n",
        "        # Test the connection with a simple query\n",
        "        graph.query(\"RETURN 1 as test\")\n",
        "        print(\"‚úÖ Neo4j connection established successfully\")\n",
        "\n",
        "        # Clear the database for a clean import\n",
        "        print(\"üßπ Clearing existing data...\")\n",
        "        graph.query(\"MATCH (n) DETACH DELETE n\")\n",
        "        print(\"‚úÖ Successfully connected to Neo4j and cleared existing data.\")\n",
        "        break\n",
        "\n",
        "    except (ServiceUnavailable, TransientError, TimeoutError) as e:\n",
        "        print(f\"‚ùå Connection error on attempt {attempt + 1}: {e}\")\n",
        "\n",
        "        if attempt < max_connection_retries - 1:\n",
        "            print(f\"‚è≥ Waiting {connection_delay} seconds before retry...\")\n",
        "            time.sleep(connection_delay)\n",
        "            connection_delay *= 2  # Exponential backoff\n",
        "        else:\n",
        "            print(f\"üí• Failed to connect to Neo4j after {max_connection_retries} attempts\")\n",
        "            raise e\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Unexpected error connecting to Neo4j: {e}\")\n",
        "        raise e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfolvM0h5c9_"
      },
      "source": [
        "## 4. Load Extracted Contract Data\n",
        "\n",
        "Here we load the `contract_data.json` file generated in Module 1.\n",
        "\n",
        "This file contains structured contract information\n",
        "\n",
        "We'll reference this data for further processing in the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_xxgixn5c9_",
        "outputId": "272d4798-79a1-4531-9714-9901b30f7afe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Successfully loaded 5 records\n",
            "[{'summary': 'Reseller promotes and solicits commitments to buy company products in the territory. Contract is renewable for 1 year extension by amendment to this agreement. Either Party may terminate this agreement for non-cause with a sixty (60) day written notice.', 'contract_type': 'Reseller', 'parties': [{'name': 'Aperture Global Logistics', 'location': {'city': 'Anytown', 'state': 'Delaware', 'country': 'US'}, 'role': 'Reseller'}, {'name': 'LogiSync Solutions Inc.', 'location': {'city': 'Silicon Valley', 'state': 'CA', 'country': 'US'}, 'role': 'Company'}], 'effective_date': '2017-04-07', 'duration': 'P1Y', 'end_date': '2018-04-07', 'governing_law': {'city': None, 'state': 'Virginia', 'country': 'US'}, 'clauses': [{'summary': \"Company shall indemnify, defend and hold Reseller harmless from and against any claim that the Company Products infringe any U.S. patent or copyright or incorporate any misappropriated trade secrets. Additionally, Reseller shall indemnify, defend and hold Company harmless from and against any claim arising out of Reseller's Activities.\", 'clause_type': 'Liability & Indemnification'}, {'summary': 'Each party acknowledges that, in the course of performing its duties under this Agreement, it may obtain from the other party, certain business, technical or financial information, all of which is confidential and proprietary', 'clause_type': 'Confidentiality & Non-Disclosure'}], 'file_id': 'Contract_05_Reseller_AGL_LogiSync'}, {'summary': 'Agreement between Innovate Solutions Inc. and Aperture Global Logistics for Innovate Solutions Inc. to provide services to Aperture Global Logistics as detailed in Exhibit A. Innovate Solutions Inc. will provide services at cost plus 10% service fee. Aperture Global Logistics will reimburse Innovate Solutions Inc. for out-of-pocket expenses. Innovate Solutions Inc. will allow Aperture Global Logistics to use a tool at no cost until December 31, 2021.', 'contract_type': 'Service', 'parties': [{'name': 'Innovate Solutions Inc.', 'location': {'city': None, 'state': None, 'country': ''}, 'role': 'Provider'}, {'name': 'Aperture Global Logistics', 'location': {'city': 'Anytown', 'state': 'Delaware', 'country': 'US'}, 'role': 'Recipient'}], 'effective_date': '2019-11-01', 'duration': None, 'end_date': '2020-12-31', 'governing_law': {'city': None, 'state': 'Delaware', 'country': 'US'}, 'clauses': [{'summary': \"Parties shall maintain confidentiality of the other party's information.\", 'clause_type': 'Confidentiality & Non-Disclosure'}, {'summary': \"Provider shall indemnify Recipient against losses arising from Provider's negligence, willful misconduct, or breach of agreement.\", 'clause_type': 'Liability & Indemnification'}], 'file_id': 'Contract_03_Services_AGL_InnovateSolutions'}, {'summary': 'Cyberdyne appoints Aperture Global Logistics as a non-exclusive, worldwide distributor for warehouse automation systems. Distributor will market and distribute products and services to customers.', 'contract_type': 'Distributor', 'parties': [{'name': 'CYBERDYNE ROBOTICS', 'location': {'city': 'Sunnyvale', 'state': 'California', 'country': 'US'}, 'role': 'Manufacturer'}, {'name': 'Aperture Global Logistics', 'location': {'city': 'Anytown', 'state': 'Delaware', 'country': 'US'}, 'role': 'Distributor'}], 'effective_date': '2010-06-08', 'duration': None, 'end_date': None, 'governing_law': {'city': None, 'state': None, 'country': 'DE'}, 'clauses': [{'summary': 'Agreement begins on the Effective Date and continues until the termination of the Strategic Alliance Agreement.', 'clause_type': 'Renewal & Termination'}, {'summary': 'Cyberdyne and Distributor agree that all Confidential Information furnished to a party will be subject to the Confidentiality Agreement.', 'clause_type': 'Confidentiality & Non-Disclosure'}, {'summary': 'Cyberdyne will defend or settle any action brought against Distributor and shall indemnify and hold Distributor harmless from any liability, damages and expenses to the extent that it is based upon a third-party claim that a Product infringes any patent, copyright or misappropriates any trade secret.', 'clause_type': 'Liability & Indemnification'}, {'summary': \"Distributor will defend or settle, indemnify and hold Cyberdyne harmless from any liability, damages and expenses based upon a third-party claim attributable to: (i) Distributor's acts or omissions not in accordance with this Agreement or (ii) any misrepresentations made by Distributor with respect to Cyberdyne or the Products or Services.\", 'clause_type': 'Liability & Indemnification'}, {'summary': \"Cyberdyne and its licensors retain all intellectual property rights in the Products. Distributor acknowledges the validity and proprietary value of Cyberdyne's trademarks. Cyberdyne shall retain sole ownership of all goodwill associated with the Products.\", 'clause_type': 'Intellectual Property'}], 'file_id': 'Contract_04_Distributor_AGL_Cyberdyne'}, {'summary': 'Master Supply Agreement between Aperture Global Logistics (Buyer) and Fonterra (USA) Inc. (Supplier) for the supply of ingredients. The agreement outlines the terms and conditions for the purchase and supply of ingredients, including specifications, quality, intellectual property, confidentiality, termination, indemnification, and other standard provisions.', 'contract_type': 'Supply', 'parties': [{'name': 'Aperture Global Logistics', 'location': {'city': 'Anytown', 'state': 'USA', 'country': 'US'}, 'role': 'Buyer'}, {'name': 'Fonterra (USA) Inc.', 'location': {'city': 'Chicago', 'state': 'IL', 'country': 'US'}, 'role': 'Supplier'}], 'effective_date': '2019-10-31', 'duration': 'P5Y', 'end_date': '2024-10-31', 'governing_law': {'city': None, 'state': 'Delaware', 'country': 'US'}, 'clauses': [{'summary': 'The agreement will automatically renew for additional periods of five (5) years unless one Party notifies the other of its intention not to renew, no less than 12 months prior to the expiration of the then-current term, unless terminated as permitted under this Agreement.', 'clause_type': 'Renewal & Termination'}, {'summary': 'Each Party will hold in strict confidence and keep confidential all Confidential Information disclosed to it by the other.', 'clause_type': 'Confidentiality & Non-Disclosure'}, {'summary': 'Each Party will defend and hold harmless the other Party and its subsidiaries, affiliates, officers, directors, employees, attorneys, insurers, shareholders, representatives and agents from and against any and all liabilities, losses, damages, claims, actions, proceedings, suits, costs or expenses, including reasonable attorney fees for counsel retained by the indemnified Party, brought by a Third Party, arising out of or in connection with any negligent or intentional act or omission of the indemnifying Party, its agents or employees.', 'clause_type': 'Liability & Indemnification'}, {'summary': 'Each Party shall retain ownership of all Intellectual Property Rights owned or licensed by that Party prior to the commencement date of this Agreement; or developed or acquired independently of this Agreement by that Party or its licensors other than in connection with this Agreement.', 'clause_type': 'Intellectual Property'}], 'file_id': 'Contract_02_MSA_AGL_Fonterra'}, {'summary': 'Road Transportation Agreement between Aperture Global Logistics (Shipper) and Tonglu Tongze Logistics Ltd. (Carrier) for parcel transportation services on highway line-haul routes. Aperture Global Logistics pays the freight, and Tonglu Tongze Logistics Ltd. provides the transportation services.', 'contract_type': 'Transportation', 'parties': [{'name': 'Aperture Global Logistics', 'location': {'city': 'Anytown', 'state': 'USA', 'country': 'US'}, 'role': 'Shipper'}, {'name': 'Tonglu Tongze Logistics Ltd.', 'location': {'city': 'Tonglu County, Zhejiang Province', 'state': None, 'country': 'CN'}, 'role': 'Carrier'}], 'effective_date': '2014-12-22', 'duration': None, 'end_date': None, 'governing_law': None, 'clauses': [{'summary': 'Party B shall provide parcel transportation services on highway line-haul routes based on the needs of Party A.', 'clause_type': 'Payment and Freight Terms'}, {'summary': 'Agreement is valid for an indefinite term.', 'clause_type': 'Renewal & Termination'}, {'summary': 'Party A pays freight based on carload rate.', 'clause_type': 'Payment and Freight Terms'}, {'summary': \"Party B shall comply with Party A's transportation arrangement and systems.\", 'clause_type': 'Liability & Indemnification'}, {'summary': 'Party B shall ensure the vehicles are in good condition.', 'clause_type': 'Liability & Indemnification'}, {'summary': 'Party B shall have valid licenses for national road transportation.', 'clause_type': 'Liability & Indemnification'}, {'summary': 'Party B shall arrive at the network partners determined by Party A according to the time and route stipulated in this Agreement, and strictly comply with the start time and end time.', 'clause_type': 'Payment and Freight Terms'}, {'summary': 'Party B shall settle vehicle malfunctions or accidents within half an hour.', 'clause_type': 'Liability & Indemnification'}, {'summary': 'Party B shall provide copies of licenses to Party A, and guarantee the authenticity, completeness, legality and validity of such licenses and materials.', 'clause_type': 'Liability & Indemnification'}, {'summary': \"Party B's drivers shall have at least two years driving experience in large trucks and have relevant licenses.\", 'clause_type': 'Liability & Indemnification'}, {'summary': 'Party B shall be responsible for driving safety.', 'clause_type': 'Liability & Indemnification'}, {'summary': 'Party B shall purchase sufficient insurance for the transportation vehicles.', 'clause_type': 'Liability & Indemnification'}, {'summary': \"Parcel damage resulting from the fault of Party B's employees shall be compensated by Party B in accordance with Party A's relevant rules.\", 'clause_type': 'Liability & Indemnification'}, {'summary': \"Party A can terminate this Agreement without any compensation if vehicle space insufficiency causes Party A's need unable to be satisfied nor can it be adjusted to satisfy Party A's need\", 'clause_type': 'Renewal & Termination'}, {'summary': 'Party A has the right to terminate this Agreement if Party B has breached the articles in this Agreement.', 'clause_type': 'Renewal & Termination'}, {'summary': 'Party B shall pay one-month freight as liquidated damages in case of termination of the Agreement without consent.', 'clause_type': 'Renewal & Termination'}, {'summary': \"Party B shall not transfer the carriage of goods to any third party in the designated route without Party A's approval.\", 'clause_type': 'Liability & Indemnification'}, {'summary': \"Any dispute arising out of the execution of this Agreement, which cannot be negotiated and settled by both Parties, shall be subject to the jurisdiction of the People's Court where this Agreement is signed.\", 'clause_type': 'Dispute Resolution'}], 'file_id': 'Contract_01_Transportation_AGL_Tonglu'}]\n"
          ]
        }
      ],
      "source": [
        "# Load the structured contract data extracted in Module 1.\n",
        "# The variable 'contract_results' will hold a list of dictionaries,\n",
        "# where each dictionary contains information about a single contract\n",
        "# (such as summary, contract_type, parties, clauses, etc.).\n",
        "\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the file (replace with your actual path)\n",
        "contract_json_filename = \"/content/drive/MyDrive/1. Learning/01_GenAI_Community_Work/02-GenAI Collab Hub/Cohort-2/Notebooks/contract_data.json\"\n",
        "\n",
        "with open(contract_json_filename, 'r') as file:\n",
        "    contract_results = json.load(file)\n",
        "\n",
        "print(f\"Successfully loaded {len(contract_results)} records\")\n",
        "print(contract_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tKxJZjY5c9_"
      },
      "source": [
        "## 5. Create Vector Embeddings\n",
        "\n",
        "Here we generate vector embeddings for each contract summary using Google's Gemini text-embedding-004 model.\n",
        "\n",
        "This code uses Gemini's embedding API, processes summaries in small batches to avoid timeouts, and implements retries for robustness.\n",
        "\n",
        "Each embedding generated by the Gemini model is attached to its corresponding contract in the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRD9ROaJ5c9_",
        "outputId": "2013505c-9076-4659-ed2f-a40a4d617ba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embeddings for 5 summaries in batches of 2...\n",
            "Processing batch 1/3: summaries [0, 1]\n",
            "‚úì Successfully embedded batch 1\n",
            "Processing batch 2/3: summaries [2, 3]\n",
            "‚úì Successfully embedded batch 2\n",
            "Processing batch 3/3: summaries [4]\n",
            "‚úì Successfully embedded batch 3\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from google.api_core import retry\n",
        "\n",
        "# if condition to check if 'contract_results' exists in the current local scope.\n",
        "# This prevents errors if the contract data failed to load or was not defined.\n",
        "if 'contract_results' in locals():\n",
        "    # Initialize the Gemini embedding model\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
        "    # Extract summaries from each contract, defaulting to empty string if missing\n",
        "    summaries = [el.get(\"summary\", \"\") for el in contract_results]\n",
        "\n",
        "    batch_size = 2  # Number of summaries to process in each batch\n",
        "    embeddings_output = []  # List to store all embeddings\n",
        "\n",
        "    print(f\"Generating embeddings for {len(summaries)} summaries in batches of {batch_size}...\")\n",
        "\n",
        "    # Process summaries in batches\n",
        "    for i in range(0, len(summaries), batch_size):\n",
        "        batch = summaries[i:i + batch_size]\n",
        "        batch_indices = list(range(i, min(i + batch_size, len(summaries))))\n",
        "        print(f\"Processing batch {i//batch_size + 1}/{(len(summaries) + batch_size - 1)//batch_size}: summaries {batch_indices}\")\n",
        "\n",
        "        max_retries = 3  # Maximum number of retry attempts for each batch\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                # Attempt to generate embeddings for the current batch using Gemini\n",
        "                batch_embeddings = embeddings.embed_documents(batch)\n",
        "                embeddings_output.extend(batch_embeddings)\n",
        "                print(f\"‚úì Successfully embedded batch {i//batch_size + 1}\")\n",
        "                break  # Exit retry loop on success\n",
        "            except Exception as e:\n",
        "                print(f\"‚úó Attempt {attempt + 1} failed for batch {i//batch_size + 1}: {e}\")\n",
        "                if attempt < max_retries - 1:\n",
        "                    wait_time = (attempt + 1) * 2  # Exponential backoff for retries\n",
        "                    print(f\"Waiting {wait_time} seconds before retry...\")\n",
        "                    time.sleep(wait_time)\n",
        "                else:\n",
        "                    print(f\"Failed to embed batch {i//batch_size + 1} after {max_retries} attempts\")\n",
        "                    raise e  # Raise exception if all retries fail\n",
        "\n",
        "        # Optional: short pause between batches to avoid rate limits\n",
        "        if i + batch_size < len(summaries):\n",
        "            time.sleep(1)\n",
        "\n",
        "    # Attach each Gemini embedding to its corresponding contract\n",
        "    for i, contract in enumerate(contract_results):\n",
        "        contract['embedding'] = embeddings_output[i]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDbcUlKf5c9_"
      },
      "source": [
        "## 6 Save Contract Embeddings to a json file\n",
        "\n",
        "Here we prepare a list of contract file IDs and their embedding vectors for Neo4j import.\n",
        "We then saves these embeddings to a JSON file for later use in the graph database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_7Wf8WT5c9_",
        "outputId": "eaba88f7-0a2e-44e9-f03d-60979cd419f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Saved embeddings to contract_embedding.json\n",
            "Successfully generated embeddings for 5 contract summaries.\n",
            "Sample embedding vector length: 768\n"
          ]
        }
      ],
      "source": [
        "params = []\n",
        "for embedding, contract in zip(embeddings_output, contract_results):\n",
        "    params.append({\"file_id\": contract[\"file_id\"], \"embedding\": embedding})\n",
        "\n",
        "with open(\"contract_embedding.json\", \"w\") as json_file:\n",
        "    json.dump(params, json_file, indent=4)\n",
        "\n",
        "print(f\"üíæ Saved embeddings to contract_embedding.json\")\n",
        "print(f\"Successfully generated embeddings for {len(embeddings_output)} contract summaries.\")\n",
        "print(f\"Sample embedding vector length: {len(contract_results[0]['embedding'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyEaFmY55c9_"
      },
      "source": [
        "## 7. Define the Graph Ingestion Query (Cypher Query for Import)\n",
        "\n",
        "Here we define the **Cypher query for importing contract data** into the Neo4j graph.\n",
        "\n",
        "This is the core of our module: the Cypher query that will build our knowledge graph. The query uses `UNWIND` to process our list of contracts in a single, efficient transaction.\n",
        "\n",
        "For each contract, it will:\n",
        "1.  **MERGE** a `Contract` node, using `file_id` as a unique key.\n",
        "2.  **SET** its properties (summary, type, dates, etc.).\n",
        "3.  **MERGE** `Party` and `Location` nodes for all parties involved, creating relationships like `:PARTY_TO` and `:HAS_LOCATION`.\n",
        "4.  **MERGE** `Clause` nodes and link them to the contract with a `:HAS_CLAUSE` relationship.\n",
        "5.  **Set** the `embedding` vector property on the `Contract` node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LTMtE_fe5c-A"
      },
      "outputs": [],
      "source": [
        "query = \"\"\"UNWIND $data AS row\n",
        "MERGE (c:Contract {file_id: row.file_id})\n",
        "SET c.summary = row.summary,\n",
        "    c.contract_type = row.contract_type,\n",
        "    c.effective_date = date(row.effective_date),\n",
        "    c.contract_scope = row.contract_scope,\n",
        "    c.duration = row.duration,\n",
        "    c.end_date = CASE WHEN row.end_date IS NOT NULL THEN date(row.end_date) ELSE NULL END,\n",
        "    c.total_amount = row.total_amount\n",
        "WITH c, row\n",
        "CALL (c, row) {\n",
        "    WITH c, row\n",
        "    WHERE row.governing_law IS NOT NULL\n",
        "    MERGE (c)-[:HAS_GOVERNING_LAW]->(l:Location)\n",
        "    SET l += row.governing_law\n",
        "}\n",
        "FOREACH (party IN row.parties |\n",
        "    MERGE (p:Party {name: party.name})\n",
        "    MERGE (p)-[:HAS_LOCATION]->(pl:Location)\n",
        "    SET pl += party.location\n",
        "    MERGE (p)-[pr:PARTY_TO]->(c)\n",
        "    SET pr.role = party.role\n",
        ")\n",
        "FOREACH (clause IN row.clauses |\n",
        "    MERGE (c)-[:HAS_CLAUSE]->(cl:Clause {type: clause.clause_type})\n",
        "    SET cl.summary = clause.summary\n",
        ")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5m9Y3Z05c-A"
      },
      "source": [
        "## 8. Execute Cypher query\n",
        "\n",
        "Here we execute the cypher query defined above to actually import all structured contract results.\n",
        "\n",
        "1. First we load previously saved contract data from the JSON file into the results variable, allowing us to reuse the parsed contract objects without re-processing the original data source.\n",
        "\n",
        "2. We create unique constraints in Neo4j to ensure data integrity:\n",
        "\n",
        "- The first constraint enforces that each Contract node must have a unique file_id property (prevents duplicate contracts).\n",
        "\n",
        "- The second constraint ensures each Party node has a unique name (prevents duplicate parties).\n",
        "\n",
        "3. Then we execute the cypher query defined above to actually import all structured contract results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvJ-NbyU5c-A",
        "outputId": "025a1614-ecf5-4722-d4d8-66ca8d43aaba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Create unique constraint for Contract nodes on file_id\n",
        "graph.query(\"CREATE CONSTRAINT IF NOT EXISTS FOR (c:Contract) REQUIRE c.file_id IS UNIQUE;\")\n",
        "# Create unique constraint for Party nodes on name\n",
        "graph.query(\"CREATE CONSTRAINT IF NOT EXISTS FOR (c:Party) REQUIRE c.name IS UNIQUE;\")\n",
        "\n",
        "# Execute Cypher query to import contract data\n",
        "graph.query(query, {\"data\": contract_results})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKgF-WJ65c-A"
      },
      "source": [
        "## 9. Add embedding vectors to contract nodes for semantic search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmGb3U6N5c-A",
        "outputId": "d1f8902a-fd4b-4cf1-c336-914f7fb38831"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "with open(\"contract_embedding.json\", \"w\") as json_file:\n",
        "    json.dump(params, json_file, indent=4)\n",
        "\n",
        "graph.query(\"\"\"UNWIND $data AS row\n",
        "MATCH (c:Contract {file_id:row.file_id})\n",
        "CALL db.create.setNodeVectorProperty(c, 'embedding', row.embedding)\"\"\",\n",
        "            {\"data\": params})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGrbQiZE5c-A"
      },
      "source": [
        "## 10. Create Vector Index\n",
        "\n",
        "- **Vector Index**: We'll create a vector index on the `embedding` property of `Contract` nodes. This is essential for enabling fast similarity searches in the next module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wqqiu4T5c-A",
        "outputId": "520975d9-3609-434a-ec78-b2324430f867"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "graph.query(\"CREATE VECTOR INDEX contractSummary IF NOT EXISTS FOR (c:Contract) ON c.embedding\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYk-RAU25c-A"
      },
      "source": [
        "### Congratulations!\n",
        "\n",
        "You have successfully completed the Ingestion Pipeline! We have now transformed raw text into a fully populated, indexed, and semantically enriched knowledge graph in Neo4j. This graph is now ready to be queried by our intelligent agent, which we will build in Module 3."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}